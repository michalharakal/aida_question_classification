# -*- coding: utf-8 -*-
"""HF_Transformers_Example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_SxwH0piQYEVX1xpJckbqwHePLqeOgV6
"""

# TODO implement in python
# !pip install transformers == 3.4.0

# wget https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-downstream/germeval18.tar.gz

# !tar xvfz germeval18.tar.gz

import pandas as pd
import sklearn
import math
import numpy as np
import random
import torch

from transformers import AutoConfig, logging, AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer
import datasets

# training params
lang_model = 'german-nlp-group/electra-base-german-uncased'
train_data_file = './germeval18/train.tsv'
test_data_file = './germeval18/test.tsv'
label_list = ["OTHER", "OFFENSE"]
text_col_name = 'text'
label_col_name = 'coarse_label'
n_gpu = 1

# set hyperparameters
dropout = 0.3
learning_rate = 2.576e-05
num_train_epochs = 2  # 11 would be better
warmup_proportion = 0.2
max_seq_len = 100
batch_size_per_gpu = 16


# dataset to store tokenized text and labels
class LabeledDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)


# metrics util function
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    f1_list = sklearn.metrics.f1_score(labels, preds, labels=list(range(len(label_list))), average=None)
    recall_list = sklearn.metrics.recall_score(labels, preds, labels=list(range(len(label_list))), average=None)

    result_dict = {}
    result_dict.update({f'f1_{label_list[i]}': score for i, score in enumerate(f1_list)})
    result_dict.update({f'recall_{label_list[i]}': score for i, score in enumerate(recall_list)})
    result_dict['acc'] = sklearn.metrics.accuracy_score(labels, preds)
    result_dict['bac'] = sklearn.metrics.balanced_accuracy_score(labels, preds)
    result_dict['mcc'] = sklearn.metrics.matthews_corrcoef(labels, preds)
    result_dict['f1_macro'] = sklearn.metrics.f1_score(labels, preds, average='macro')

    return result_dict


# data loading
def load_data(filename, text_col_name, label_col_name, label_list, tokenizer, max_seq_len):
    # load data
    df = pd.read_csv(filename, sep='\t')
    data_text = df[text_col_name].tolist()
    data_label = df[label_col_name].tolist()
    assert len(data_text) == len(data_label)

    # encode label
    data_label_encoded = [label_list.index(l) for l in data_label]
    assert len(data_label_encoded) == len(data_label)

    data_text_encoded = tokenizer(
        data_text,
        truncation=True,
        padding='max_length',
        max_length=max_seq_len,
        return_token_type_ids=False,
    )

    labeled_dataset = LabeledDataset(data_text_encoded, data_label_encoded)

    print(f'LabeledDataset of len {len(labeled_dataset)} loaded. Source file: {filename}')

    return labeled_dataset, data_label_encoded


def main():

    logging.set_verbosity_info()
    # load and create tokenizer
    tokenizer = AutoTokenizer.from_pretrained(lang_model)

    # preprocess and create train dataset
    labeled_dataset_train, _ = load_data(
        filename=train_data_file,
        text_col_name=text_col_name,
        label_col_name=label_col_name,
        label_list=label_list,
        tokenizer=tokenizer,
        max_seq_len=max_seq_len,
    )

    # preprocess and create test dataset
    labeled_dataset_test, _ = load_data(
        filename=test_data_file,
        text_col_name=text_col_name,
        label_col_name=label_col_name,
        label_list=label_list,
        tokenizer=tokenizer,
        max_seq_len=max_seq_len,
    )

    # calculate more parameters
    total_batch_size = batch_size_per_gpu * n_gpu
    num_train_samples = len(labeled_dataset_train)
    steps_per_epoch = math.ceil(num_train_samples / total_batch_size)
    steps_total = steps_per_epoch * num_train_epochs
    warmup_steps = int(warmup_proportion * steps_total)

    # model training config
    config = AutoConfig.from_pretrained(
        lang_model,
        num_labels=len(label_list),
    )
    config.summary_last_dropout = dropout

    # create and load model
    model = AutoModelForSequenceClassification.from_pretrained(
        lang_model,
        config=config,
    )

    # training config
    training_args = TrainingArguments(
        num_train_epochs=num_train_epochs,
        per_device_train_batch_size=batch_size_per_gpu,
        per_device_eval_batch_size=batch_size_per_gpu,
        learning_rate=learning_rate,
        gradient_accumulation_steps=1,
        warmup_steps=warmup_steps,

        output_dir='.',
        overwrite_output_dir=True,
        save_steps=0,
        logging_dir=None,
        logging_steps=0,
        evaluation_strategy='epoch',

        disable_tqdm=False,
    )

    # create trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=labeled_dataset_train,
        eval_dataset=labeled_dataset_test,
        compute_metrics=compute_metrics,
    )

    # train and get results
    trainer.train()
    train_result = trainer.state.log_history[-1]
    print(train_result)


if __name__ == '__main__':
    main()
