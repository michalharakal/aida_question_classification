{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variants of basic SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization with parameter C shows some slight improvements in the cross_val_score\n",
    "see below pipe_tf_plus for the TfidfVectorizer model and  pipe_cv_ng12_plus  for the CountVectorizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other variants attempted: \n",
    "#instead of svm.LinearSVC(): svm.SVC(kernel='rbf'): no improvement of cv score\n",
    "#when class_weight='balanced', i.e. : ConvergenceWarning: Liblinear failed to converge, increase the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/an/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/an/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_words shape (5452, 61818)\n",
      "(5452, 8411)\n",
      "cross_val_score, TfidfVectorized : 0.8308879153036941\n",
      "cross_val_score, TfidfVectorized : 0.8321709735197909\n",
      "cross_val_score, CountVectorized  pipe_cv_no_stop_words: 0.8277667992499096\n",
      "cross_val_score, pipe_cv_no_stop_words ngram_range=(1, 2) : 0.8556484666033182\n",
      "cross_val_score, pipe_cv_no_stop_words ngram_range=(1, 2) plus: 0.8561985889555075\n",
      "cross_val_score, pipe_cv_no_stop_words ngram_range=(1, 3) : 0.8488609894129617\n",
      "results TfidfVectorized pipeline fkt:\n",
      "accuracy_score: CountVectorized 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.83      0.97      0.89       138\n",
      "        ENTY       0.87      0.70      0.78        94\n",
      "         HUM       0.89      0.95      0.92        65\n",
      "         LOC       0.85      0.86      0.86        81\n",
      "         NUM       0.97      0.88      0.93       113\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.90      0.86      0.87       500\n",
      "weighted avg       0.88      0.88      0.88       500\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  7   2   0   0   0   0]\n",
      " [  0 134   3   0   0   1]\n",
      " [  0  16  66   5   7   0]\n",
      " [  0   1   1  62   1   0]\n",
      " [  0   5   3   1  70   2]\n",
      " [  0   4   3   2   4 100]]\n",
      "results TfidfVectorized pipeline fkt  plus:\n",
      "accuracy_score: CountVectorized 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.83      0.98      0.90       138\n",
      "        ENTY       0.87      0.69      0.77        94\n",
      "         HUM       0.90      0.95      0.93        65\n",
      "         LOC       0.83      0.86      0.85        81\n",
      "         NUM       0.98      0.88      0.93       113\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.90      0.86      0.87       500\n",
      "weighted avg       0.88      0.88      0.88       500\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  7   2   0   0   0   0]\n",
      " [  0 135   3   0   0   0]\n",
      " [  0  15  65   5   9   0]\n",
      " [  0   1   1  62   1   0]\n",
      " [  0   5   3   1  70   2]\n",
      " [  0   5   3   1   4 100]]\n",
      "results CountVectorized pipeline fkt:\n",
      "accuracy_score: CountVectorized 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.80      0.99      0.89       138\n",
      "        ENTY       0.88      0.74      0.80        94\n",
      "         HUM       0.90      0.92      0.91        65\n",
      "         LOC       0.88      0.81      0.85        81\n",
      "         NUM       0.98      0.87      0.92       113\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.91      0.85      0.87       500\n",
      "weighted avg       0.88      0.88      0.87       500\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  7   2   0   0   0   0]\n",
      " [  0 137   1   0   0   0]\n",
      " [  0  14  70   5   5   0]\n",
      " [  0   3   2  60   0   0]\n",
      " [  0   8   4   1  66   2]\n",
      " [  0   7   3   1   4  98]]\n",
      "results pipe_cv_no_stop_words ngram_range=(1, 2) fkt:\n",
      "accuracy_score: CountVectorized 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.81      0.99      0.89       138\n",
      "        ENTY       0.84      0.76      0.79        94\n",
      "         HUM       0.92      0.92      0.92        65\n",
      "         LOC       0.93      0.88      0.90        81\n",
      "         NUM       1.00      0.88      0.93       113\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.92      0.87      0.89       500\n",
      "weighted avg       0.90      0.89      0.89       500\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  7   2   0   0   0   0]\n",
      " [  0 136   2   0   0   0]\n",
      " [  0  17  71   4   2   0]\n",
      " [  0   1   3  60   1   0]\n",
      " [  0   4   6   0  71   0]\n",
      " [  0   8   3   1   2  99]]\n",
      "results pipe_cv_no_stop_words ngram_range=(1, 2) fkt plus:\n",
      "accuracy_score: CountVectorized 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.81      0.99      0.89       138\n",
      "        ENTY       0.84      0.76      0.79        94\n",
      "         HUM       0.92      0.92      0.92        65\n",
      "         LOC       0.93      0.88      0.90        81\n",
      "         NUM       1.00      0.88      0.93       113\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.92      0.87      0.89       500\n",
      "weighted avg       0.90      0.89      0.89       500\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  7   2   0   0   0   0]\n",
      " [  0 136   2   0   0   0]\n",
      " [  0  17  71   4   2   0]\n",
      " [  0   1   3  60   1   0]\n",
      " [  0   4   6   0  71   0]\n",
      " [  0   8   3   1   2  99]]\n",
      "results pipe_cv_no_stop_words ngram_range=(1, 3) fkt:\n",
      "accuracy_score: CountVectorized 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.78      0.88         9\n",
      "        DESC       0.81      0.99      0.89       138\n",
      "        ENTY       0.83      0.76      0.79        94\n",
      "         HUM       0.94      0.91      0.92        65\n",
      "         LOC       0.92      0.88      0.90        81\n",
      "         NUM       1.00      0.88      0.93       113\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.92      0.86      0.88       500\n",
      "weighted avg       0.89      0.89      0.89       500\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  7   2   0   0   0   0]\n",
      " [  0 136   2   0   0   0]\n",
      " [  0  17  71   3   3   0]\n",
      " [  0   1   4  59   1   0]\n",
      " [  0   4   6   0  71   0]\n",
      " [  0   8   3   1   2  99]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import data.get_data as data\n",
    "import utils.text_manipulation as text\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "def preprocess(df_train, df_test):\n",
    "    \"\"\"\n",
    "    cleaning text file / question column of DF with regex, of stopwords and apply lemmatizer\n",
    "\n",
    "    :param df_train: train DF\n",
    "    :param df_test: test DF\n",
    "    :return:\n",
    "        df_train, df_test Data Frames\n",
    "    \"\"\"\n",
    "\n",
    "    # apply regex textcleaning\n",
    "    df_train['text'] = df_train.question.apply(text.clean_text)\n",
    "    df_test['text'] = df_test.question.apply(text.clean_text)\n",
    "\n",
    "    # apply stopword manipulation\n",
    "    df_train['text'] = df_train.text.apply(text.stopword_text)\n",
    "    df_test['text'] = df_test.text.apply(text.stopword_text)\n",
    "\n",
    "    # apply lemmatizer\n",
    "    df_train['text'] = df_train.text.apply(text.lem_text)\n",
    "    df_test['text'] = df_test.text.apply(text.lem_text)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def evaluate_pipeline(pipeline, X_test, y_test):\n",
    "    \"\"\"\n",
    "    print pipeline results for given pipeline and X, y values\n",
    "\n",
    "    :param pipeline: fitted sklearn pipeline\n",
    "    :param X_test: X_test values\n",
    "    :param y_test: y_test values\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred_pipeline = pipeline.predict(X_test)\n",
    "\n",
    "    print('accuracy_score: CountVectorized', accuracy_score(y_test, y_pred_pipeline))\n",
    "\n",
    "    report = classification_report(y_test, y_pred_pipeline)\n",
    "    print(report)\n",
    "\n",
    "    val_confusion_matrix = confusion_matrix(y_test, y_pred_pipeline)\n",
    "    print(f'Confusion Matrix: \\n{val_confusion_matrix}')\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    # loading data and working with pd df\n",
    "    df_train = data.get_train_data()\n",
    "    df_test = data.get_test_data()\n",
    "\n",
    "    # preprocess questions regex clean, stopwords, lemmatizer\n",
    "    df_train, df_test = preprocess(df_train, df_test)\n",
    "\n",
    "    # defining main test and train data of main categories\n",
    "    # X_train = df_train['text'] # question - data regex, stopwords, lem\n",
    "    X_train = df_train['question'] # question - data not cleaned\n",
    "    y_train = df_train['category']  # using main category\n",
    "\n",
    "    # X_test = df_test['text']  # question - data not cleaned\n",
    "    X_test = df_test['question'] # question - data not cleaned\n",
    "    y_test = df_test['category']  # using main category\n",
    "\n",
    "    # Test - defining main test and train data of main sub categories\n",
    "    # X_train = df_train.text\n",
    "    # y_train = df_train['subcategory']  # using main category\n",
    "    # X_test = df_test.text\n",
    "    # y_test = df_test['subcategory']  # using main category\n",
    "\n",
    "    # create CountVectorizer to validate in df the use of it.\n",
    "    # later not used directly only applied in Pipeline\n",
    "    # ngram_range=(1, 2),\n",
    "    count_vectorizer = CountVectorizer(stop_words=[], ngram_range=(1, 3))\n",
    "    bag_of_words = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # Show the Bag-of-Words Model as a pandas DataFrame\n",
    "    feature_names = count_vectorizer.get_feature_names()\n",
    "    df_bag_of_words = pd.DataFrame(bag_of_words.toarray(), columns=feature_names)\n",
    "\n",
    "    # print(type(bag_of_words))\n",
    "    print('bag_of_words shape', bag_of_words.shape)\n",
    "\n",
    "    # create vectorizer out of words of questions\n",
    "    # later not used directly only applied in Pipeline\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # Show the Model as a pandas DataFrame\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    df_tfidf_vectorizer = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "    # print(type(tfidf_matrix))\n",
    "    print(tfidf_matrix.shape)\n",
    "\n",
    "\n",
    "    # prediction\n",
    "\n",
    "    pipe_tf = Pipeline(steps=[\n",
    "        ('data_vec', TfidfVectorizer()),\n",
    "        # ('model', LogisticRegressionCV())\n",
    "        ('model', svm.LinearSVC(C=1))  # \n",
    "    ])\n",
    "    print('cross_val_score, TfidfVectorized :', cross_val_score(pipe_tf, X_train, y_train).mean())\n",
    "\n",
    "    pipe_tf_plus = Pipeline(steps=[\n",
    "        ('data_vec', TfidfVectorizer()),\n",
    "        # ('model', LogisticRegressionCV())\n",
    "        ('model', svm.LinearSVC(C=0.8))  # \n",
    "    ])\n",
    "    print('cross_val_score, TfidfVectorized :', cross_val_score(pipe_tf_plus, X_train, y_train).mean())\n",
    "\n",
    "    \n",
    "    pipe_cv = Pipeline(steps=[\n",
    "        ('data_cv', CountVectorizer(stop_words=[])),\n",
    "        # ('model', LogisticRegressionCV())\n",
    "        ('model', svm.LinearSVC())\n",
    "    ])\n",
    "    print('cross_val_score, CountVectorized  pipe_cv_no_stop_words:', cross_val_score(pipe_cv, X_train, y_train).mean())\n",
    "\n",
    "    pipe_cv_ng12 = Pipeline(steps=[\n",
    "        ('data_cv', CountVectorizer(stop_words=[], ngram_range=(1, 2))),\n",
    "        # ('model', LogisticRegressionCV())\n",
    "        ('model', svm.LinearSVC())\n",
    "    ])\n",
    "    print('cross_val_score, pipe_cv_no_stop_words ngram_range=(1, 2) :', cross_val_score(pipe_cv_ng12, X_train, y_train).mean())\n",
    "\n",
    "    pipe_cv_ng12_plus = Pipeline(steps=[\n",
    "        ('data_cv', CountVectorizer(stop_words=[], ngram_range=(1, 2))),\n",
    "        # ('model', LogisticRegressionCV())\n",
    "        ('model', svm.LinearSVC(C=0.7))\n",
    "    ])\n",
    "    print('cross_val_score, pipe_cv_no_stop_words ngram_range=(1, 2) plus:', cross_val_score(pipe_cv_ng12_plus, X_train, y_train).mean())\n",
    "\n",
    "    \n",
    "    pipe_cv_ng13 = Pipeline(steps=[\n",
    "        ('data_cv', CountVectorizer(stop_words=[], ngram_range=(1, 3))),\n",
    "        # ('model', LogisticRegressionCV())\n",
    "        ('model', svm.LinearSVC())\n",
    "    ])\n",
    "    print('cross_val_score, pipe_cv_no_stop_words ngram_range=(1, 3) :',\n",
    "          cross_val_score(pipe_cv_ng13, X_train, y_train).mean())\n",
    "\n",
    "    ##############################\n",
    "    # Measuring the performance\n",
    "    # Testing the pipeline models using Count Vectorized and again with Tfi-df Vectorized.\n",
    "\n",
    "    pipe_tf.fit(X_train, y_train)\n",
    "    print('results TfidfVectorized pipeline fkt:')\n",
    "    evaluate_pipeline(pipe_tf, X_test, y_test)\n",
    "    \n",
    "    pipe_tf_plus.fit(X_train, y_train)\n",
    "    print('results TfidfVectorized pipeline fkt  plus:')\n",
    "    evaluate_pipeline(pipe_tf_plus, X_test, y_test)\n",
    "\n",
    "    pipe_cv.fit(X_train, y_train)\n",
    "    print('results CountVectorized pipeline fkt:')\n",
    "    evaluate_pipeline(pipe_cv, X_test, y_test)\n",
    "\n",
    "    pipe_cv_ng12.fit(X_train, y_train)\n",
    "    print('results pipe_cv_no_stop_words ngram_range=(1, 2) fkt:')\n",
    "    evaluate_pipeline(pipe_cv_ng12, X_test, y_test)\n",
    "    \n",
    "    pipe_cv_ng12_plus.fit(X_train, y_train)\n",
    "    print('results pipe_cv_no_stop_words ngram_range=(1, 2) fkt plus:')\n",
    "    evaluate_pipeline(pipe_cv_ng12_plus, X_test, y_test)\n",
    "\n",
    "    pipe_cv_ng13.fit(X_train, y_train)\n",
    "    print('results pipe_cv_no_stop_words ngram_range=(1, 3) fkt:')\n",
    "    evaluate_pipeline(pipe_cv_ng13, X_test, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "    \n",
    "#Variants attempted: \n",
    "#instead of svm.LinearSVC(): svm.SVC(kernel='rbf'): no improvement of cv score\n",
    "#when class_weight='balanced', i.e. : ConvergenceWarning: Liblinear failed to converge, increase the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
