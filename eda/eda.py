# -*- coding: utf-8 -*-
"""Kopie von Group_A_AN_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SJI3LUb1Tu66tqd6mA1SUcQpVq0uPd1u

EDA

https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label

https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label

##Libaries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""#Load & Explore"""

def process_question(row):
   return " ".join(row.split(" ")[1:])

train_df = pd.read_table("https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label", encoding = "ISO-8859-1", header=None)
train_df.columns = ["raw"]
train_df['category'] = train_df.apply (lambda row: row["raw"].split(":")[0], axis=1)
train_df['subcategory'] = train_df.apply (lambda row: row["raw"].split(" ")[0].split(":")[1], axis=1)
train_df['question'] = train_df.apply (lambda row: process_question(row["raw"]), axis=1)

train_df

train_df.nunique()

train_df.shape

train_df.head(5)

train_df.columns

def process_question(row):
   return " ".join(row.split(" ")[1:])

test_df = pd.read_table("https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label", encoding = "ISO-8859-1", header=None)
test_df.columns = ["raw"]
test_df['category'] = train_df.apply (lambda row: row["raw"].split(":")[0], axis=1)
test_df['subcategory'] = train_df.apply (lambda row: row["raw"].split(" ")[0].split(":")[1], axis=1)
test_df['question'] = train_df.apply (lambda row: process_question(row["raw"]), axis=1)

test_df

test_df.nunique()

# print test, train shape
print(f'shapes:\ntrain: {train_df.shape}\ttest: {test_df.shape}')

# number of row of columns
print(f'train_size:\t{train_df.size}')
print(f'test_size:\t{test_df.size}')

display('---train ---', train_df.describe())
display('---test ---', test_df.describe())

#which categories?
print(f"unique catagories: {train_df['category'].unique()}")

#same categories in train and test?
train_df['category'].unique() == test_df['category'].unique()

# distribution categories (train)
dist_train_cat = train_df.groupby('category')['subcategory'].count()
print(dist_train_cat)
dist_train_cat.sort_values(ascending=False)

#visualisation 
dist_train_cat.plot.pie()
plt.title('catagories train data');

# distribution categories (test)
dist_test_cat = test_df.groupby('category')['subcategory'].count()
dist_test_cat.sort_values(ascending=False)
print(dist_test_cat)

dist_test_cat.plot.pie()
plt.title('catagories test data');

# distribution subcategories (train)
dist_train_sub = train_df.subcategory.groupby(train_df['category']).value_counts()
print(dist_train_sub,'\n')
print(f'first 20: {dist_train_sub.sort_values(ascending=False)[:20]}')

plt.figure()
dist_train_sub.sort_values(ascending=False).plot.bar()
plt.title('subcat train');

dist_test_sub = test_df.subcategory.groupby(test_df['category']).value_counts()
print(dist_test_sub)

dist_test_sub.sort_values(ascending=False).plot.bar()
plt.title('subcat test');

#test_df with only 38 subcategories compared to 47 in train_df

n = 14   #input for nlargest
train_df.subcategory.value_counts().nlargest(n).sum()

p = (train_df.subcategory.value_counts().nlargest(n).sum())/len(train_df)
print(f'the {n} largest subcategories account for a proportion of {p}')

train_df.subcategory.value_counts().nlargest(n)

top_subcategories = list((train_df.subcategory.value_counts().nlargest(n)).index)
top_subcategories

train_df_top = train_df.loc[train_df['subcategory'].isin(top_subcategories)]
len(train_df_top)

train_df_top.sample(10)

train_df_top.subcategory.groupby(train_df['category']).value_counts()

#More than 80% of the data can be assigned to only 14 out of 47 subcategories in train_df



test_df.subcategory.value_counts().nlargest(39)


if __name__ == '__main__' :
    main()

